# flask_app.py - ä¼˜åŒ–ç‰ˆï¼Œé¿å…translateåº“å¡é¡¿
from flask import Flask, render_template, request, jsonify, send_file
import json
import pandas as pd
from pathlib import Path
import os
import tempfile
import random
import re
from collections import defaultdict
import hashlib
import threading
import queue

app = Flask(__name__)

# ========== é…ç½®è·¯å¾„ ==========
BASE_DIR = Path(__file__).parent.absolute()
CORPUS_PATH = BASE_DIR / "data" / "raw" / "medical_corpus.json"
QUESTIONS_PATH = BASE_DIR / "data" / "raw" / "medical_questions.json"

# ========== ç¿»è¯‘é˜Ÿåˆ—ç³»ç»Ÿï¼ˆé¿å…å¡é¡¿ï¼‰ ==========
class TranslationQueue:
    def __init__(self):
        self.queue = queue.Queue()
        self.results = {}
        self.worker_thread = None
        self.start_worker()
    
    def start_worker(self):
        """å¯åŠ¨ç¿»è¯‘å·¥ä½œçº¿ç¨‹"""
        self.worker_thread = threading.Thread(target=self._translation_worker, daemon=True)
        self.worker_thread.start()
        print("âœ… ç¿»è¯‘é˜Ÿåˆ—å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")
    
    def _translation_worker(self):
        """ç¿»è¯‘å·¥ä½œçº¿ç¨‹"""
        from translate import Translator
        
        # åˆ›å»ºtranslatorå®ä¾‹
        translator_en_to_zh = Translator(to_lang="zh", from_lang="en")
        translator_zh_to_en = Translator(to_lang="en", from_lang="zh")
        
        while True:
            try:
                task = self.queue.get()
                if task is None:  # åœæ­¢ä¿¡å·
                    break
                    
                task_id, text, direction = task
                
                try:
                    if direction == 'en_to_zh':
                        result = translator_en_to_zh.translate(text)
                    else:  # zh_to_en
                        result = translator_zh_to_en.translate(text)
                    
                    self.results[task_id] = result
                except Exception as e:
                    print(f"ç¿»è¯‘å¤±è´¥ ({direction}): {e}")
                    self.results[task_id] = text  # å¤±è´¥æ—¶è¿”å›åŸæ–‡æœ¬
                    
                self.queue.task_done()
                
            except Exception as e:
                print(f"ç¿»è¯‘å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
    
    def translate(self, text, direction='en_to_zh', timeout=10):
        """æäº¤ç¿»è¯‘ä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰"""
        if not text or not any('a' <= char.lower() <= 'z' for char in text) if direction == 'en_to_zh' else not any('\u4e00' <= char <= '\u9fff' for char in text):
            return text
        
        task_id = hashlib.md5(f"{text}_{direction}".encode()).hexdigest()
        
        # å¦‚æœå·²ç»æœ‰ç»“æœï¼Œç›´æ¥è¿”å›
        if task_id in self.results:
            return self.results[task_id]
        
        # æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
        self.queue.put((task_id, text, direction))
        
        # ç­‰å¾…ç»“æœï¼ˆå¸¦è¶…æ—¶ï¼‰
        start_time = time.time()
        while task_id not in self.results:
            if time.time() - start_time > timeout:
                print(f"ç¿»è¯‘è¶…æ—¶: {text[:50]}...")
                return text  # è¶…æ—¶è¿”å›åŸæ–‡æœ¬
            time.sleep(0.1)
        
        return self.results.get(task_id, text)

# åˆå§‹åŒ–ç¿»è¯‘é˜Ÿåˆ—
try:
    from translate import Translator
    translation_queue = TranslationQueue()
    HAS_TRANSLATE = True
    print("âœ… translateåº“å·²æˆåŠŸåˆå§‹åŒ–ï¼ˆä½¿ç”¨é˜Ÿåˆ—ç³»ç»Ÿï¼‰")
except ImportError as e:
    HAS_TRANSLATE = False
    print(f"âš ï¸  translateåº“æœªå®‰è£…: {e}")
    translation_queue = None

# ========== ä¼˜åŒ–ç¿»è¯‘å‡½æ•° ==========
import time

def translate_to_chinese_fast(text):
    """å¿«é€Ÿç¿»è¯‘æˆä¸­æ–‡ï¼ˆä½¿ç”¨ç¼“å­˜å’Œé˜Ÿåˆ—ï¼‰"""
    if not text or not isinstance(text, str):
        return text or ""
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¿»è¯‘
    if not any('a' <= char.lower() <= 'z' for char in text):
        return text
    
    # ä½¿ç”¨ç¿»è¯‘é˜Ÿåˆ—
    if translation_queue:
        return translation_queue.translate(text, direction='en_to_zh', timeout=5)
    
    # é™çº§åˆ°ç®€æ˜“ç¿»è¯‘
    return simple_translate_to_chinese(text)

def translate_to_english_fast(text):
    """å¿«é€Ÿç¿»è¯‘æˆè‹±æ–‡ï¼ˆä½¿ç”¨ç¼“å­˜å’Œé˜Ÿåˆ—ï¼‰"""
    if not text or not isinstance(text, str):
        return text or ""
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¿»è¯‘
    if not any('\u4e00' <= char <= '\u9fff' for char in text):
        return text
    
    # ä½¿ç”¨ç¿»è¯‘é˜Ÿåˆ—
    if translation_queue:
        return translation_queue.translate(text, direction='zh_to_en', timeout=5)
    
    # é™çº§åˆ°ç®€æ˜“ç¿»è¯‘
    return simple_translate_to_english(text)

def simple_translate_to_chinese(text):
    """ç®€æ˜“ç¿»è¯‘ï¼šè‹±æ–‡åˆ°ä¸­æ–‡ï¼ˆå¤‡ä»½æ–¹æ¡ˆï¼‰"""
    if not text:
        return text
    
    # å…³é”®åŒ»å­¦æœ¯è¯­ç¿»è¯‘
    medical_terms = {
        'skin cancer': 'çš®è‚¤ç™Œ',
        'cancer': 'ç™Œç—‡',
        'diabetes': 'ç³–å°¿ç—…',
        'high blood pressure': 'é«˜è¡€å‹',
        'pneumonia': 'è‚ºç‚',
        'heart disease': 'å¿ƒè„ç—…',
        'common cold': 'æ™®é€šæ„Ÿå†’',
        'basal cell carcinoma': 'åŸºåº•ç»†èƒç™Œ',
        'squamous cell carcinoma': 'é³çŠ¶ç»†èƒç™Œ',
        'nonmelanoma': 'éé»‘è‰²ç´ ç˜¤',
        'melanoma': 'é»‘è‰²ç´ ç˜¤',
        'CSCC': 'çš®è‚¤é³çŠ¶ç»†èƒç™Œ',
        'BCC': 'åŸºåº•ç»†èƒç™Œ',
    }
    
    result = text
    for en, zh in medical_terms.items():
        if en.lower() in result.lower():
            result = re.sub(r'\b' + re.escape(en) + r'\b', zh, result, flags=re.IGNORECASE)
    
    return result

def simple_translate_to_english(text):
    """ç®€æ˜“ç¿»è¯‘ï¼šä¸­æ–‡åˆ°è‹±æ–‡ï¼ˆå¤‡ä»½æ–¹æ¡ˆï¼‰"""
    if not text:
        return text
    
    medical_terms = {
        'çš®è‚¤ç™Œ': 'skin cancer',
        'ç™Œç—‡': 'cancer',
        'ç³–å°¿ç—…': 'diabetes',
        'é«˜è¡€å‹': 'high blood pressure',
        'è‚ºç‚': 'pneumonia',
        'å¿ƒè„ç—…': 'heart disease',
        'æ„Ÿå†’': 'common cold',
        'åŸºåº•ç»†èƒç™Œ': 'basal cell carcinoma',
        'é³çŠ¶ç»†èƒç™Œ': 'squamous cell carcinoma',
        'éé»‘è‰²ç´ ç˜¤': 'nonmelanoma',
        'é»‘è‰²ç´ ç˜¤': 'melanoma',
    }
    
    result = text
    for zh, en in medical_terms.items():
        if zh in result:
            result = result.replace(zh, en)
    
    return result

def ensure_pure_chinese(text):
    """ç¡®ä¿æ–‡æœ¬æ˜¯çº¯ä¸­æ–‡"""
    if not text:
        return text
    
    if any('a' <= char.lower() <= 'z' for char in text):
        return translate_to_chinese_fast(text)
    
    return text

def ensure_pure_english(text):
    """ç¡®ä¿æ–‡æœ¬æ˜¯çº¯è‹±æ–‡"""
    if not text:
        return text
    
    if any('\u4e00' <= char <= '\u9fff' for char in text):
        return translate_to_english_fast(text)
    
    return text

# ========== æ•°æ®åŠ è½½å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼Œé¿å…åœ¨åŠ è½½æ—¶ç¿»è¯‘ï¼‰ ==========
def load_corpus_data():
    """åŠ è½½è¯­æ–™åº“æ•°æ®"""
    try:
        if CORPUS_PATH.exists():
            with open(CORPUS_PATH, 'r', encoding='utf-8') as f:
                corpus = json.load(f)
            
            if isinstance(corpus, dict) and 'context' in corpus:
                context = corpus.get('context', '')
                paragraphs = [p.strip() for p in context.split('\n\n') if p.strip()]
                
                return {
                    'corpus_name': corpus.get('corpus_name', 'åŒ»ç–—çŸ¥è¯†åº“'),
                    'doc_count': 1,
                    'paragraphs': paragraphs,
                    'full_content': context
                }
        else:
            print(f"è¯­æ–™åº“æ–‡ä»¶ä¸å­˜åœ¨: {CORPUS_PATH}")
        return None
    except Exception as e:
        print(f"åŠ è½½è¯­æ–™åº“å¤±è´¥: {e}")
        return None

def load_questions_data():
    """åŠ è½½é—®é¢˜é›†æ•°æ®ï¼ˆä¸è¿›è¡Œç¿»è¯‘ï¼Œå»¶è¿Ÿç¿»è¯‘ï¼‰"""
    try:
        if QUESTIONS_PATH.exists():
            with open(QUESTIONS_PATH, 'r', encoding='utf-8') as f:
                questions = json.load(f)
            
            if isinstance(questions, list):
                question_types = defaultdict(int)
                all_questions = []
                
                for q in questions:
                    if isinstance(q, dict) and 'question' in q and 'answer' in q:
                        q_type = q.get('question_type', 'å…¶ä»–')
                        question_types[q_type] += 1
                        
                        question_text = q.get('question', '')
                        answer_text = q.get('answer', '')
                        
                        # åˆ¤æ–­åŸå§‹è¯­è¨€ï¼Œä½†ä¸ç«‹å³ç¿»è¯‘
                        has_chinese = any('\u4e00' <= char <= '\u9fff' for char in question_text)
                        
                        if has_chinese:
                            # åŸå§‹æ˜¯ä¸­æ–‡ï¼Œä¿å­˜åŸæ–‡æœ¬
                            question_cn = question_text
                            answer_cn = answer_text
                            # è‹±æ–‡ç‰ˆæœ¬å…ˆè®¾ä¸ºç©ºï¼Œéœ€è¦æ—¶å†ç¿»è¯‘
                            question_en = ""
                            answer_en = ""
                        else:
                            # åŸå§‹æ˜¯è‹±æ–‡ï¼Œä¿å­˜åŸæ–‡æœ¬
                            question_en = question_text
                            answer_en = answer_text
                            # ä¸­æ–‡ç‰ˆæœ¬å…ˆè®¾ä¸ºç©ºï¼Œéœ€è¦æ—¶å†ç¿»è¯‘
                            question_cn = ""
                            answer_cn = ""
                        
                        all_questions.append({
                            'question_cn': question_cn,
                            'question_en': question_en,
                            'answer_cn': answer_cn,
                            'answer_en': answer_en,
                            'type': q_type,
                            'source': q.get('source', 'Medical'),
                            'original_lang': 'zh' if has_chinese else 'en',
                            'raw_question': question_text,  # ä¿å­˜åŸå§‹é—®é¢˜
                            'raw_answer': answer_text,      # ä¿å­˜åŸå§‹ç­”æ¡ˆ
                        })
                
                sample_questions = all_questions[:50] if len(all_questions) > 50 else all_questions
                
                return {
                    'total_count': len(all_questions),
                    'sample_questions': sample_questions,
                    'question_types': dict(question_types),
                    'all_questions': all_questions
                }
        else:
            print(f"é—®é¢˜é›†æ–‡ä»¶ä¸å­˜åœ¨: {QUESTIONS_PATH}")
        return None
    except Exception as e:
        print(f"åŠ è½½é—®é¢˜é›†å¤±è´¥: {e}")
        return None

def get_data_counts():
    """è·å–æ•°æ®ç»Ÿè®¡"""
    corpus_data = load_corpus_data()
    questions_data = load_questions_data()
    
    doc_count = corpus_data['doc_count'] if corpus_data else 1
    question_count = questions_data['total_count'] if questions_data else 0
    
    return doc_count, question_count, corpus_data, questions_data

# ========== æ™ºèƒ½æœç´¢å‡½æ•°ï¼ˆå»¶è¿Ÿç¿»è¯‘ï¼‰ ==========
def search_in_questions(query, questions_data, answer_language='zh', top_k=5):
    """æ™ºèƒ½æœç´¢ç®—æ³•ï¼ˆå»¶è¿Ÿç¿»è¯‘ï¼‰"""
    if not questions_data or 'all_questions' not in questions_data:
        return []
    
    query = query.strip()
    if not query:
        return []
    
    # åˆ¤æ–­æŸ¥è¯¢è¯­è¨€
    has_chinese = any('\u4e00' <= char <= '\u9fff' for char in query)
    query_lang = 'zh' if has_chinese else 'en'
    
    results = []
    
    for q in questions_data['all_questions']:
        score = 0
        
        # è·å–åŸå§‹æ–‡æœ¬
        raw_question = q.get('raw_question', '')
        raw_answer = q.get('raw_answer', '')
        original_lang = q.get('original_lang', 'en')
        
        # æ ¹æ®æŸ¥è¯¢è¯­è¨€è¿›è¡ŒåŒ¹é…ï¼ˆä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼‰
        if query_lang == 'zh':
            # ä¸­æ–‡æŸ¥è¯¢
            query_lower = query.lower()
            if original_lang == 'zh':
                # åŸå§‹æ˜¯ä¸­æ–‡ï¼Œç›´æ¥åŒ¹é…
                if query_lower in raw_question.lower():
                    score += 10
                elif any(word in raw_question.lower() for word in query_lower.split()):
                    score += 5
            else:
                # åŸå§‹æ˜¯è‹±æ–‡ï¼Œç¿»è¯‘ååŒ¹é…
                translated_question = simple_translate_to_chinese(raw_question)
                if query_lower in translated_question.lower():
                    score += 8
        else:
            # è‹±æ–‡æŸ¥è¯¢
            query_lower = query.lower()
            if original_lang == 'en':
                # åŸå§‹æ˜¯è‹±æ–‡ï¼Œç›´æ¥åŒ¹é…
                if query_lower in raw_question.lower():
                    score += 10
                elif any(word in raw_question.lower() for word in query_lower.split()):
                    score += 5
            else:
                # åŸå§‹æ˜¯ä¸­æ–‡ï¼Œç¿»è¯‘ååŒ¹é…
                translated_question = simple_translate_to_english(raw_question)
                if query_lower in translated_question.lower():
                    score += 8
        
        if score > 0:
            # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„å›ç­”è¯­è¨€é€‰æ‹©æ˜¾ç¤ºå†…å®¹ï¼ˆå»¶è¿Ÿç¿»è¯‘ï¼‰
            if answer_language == 'en':
                # è‹±æ–‡å›ç­”
                if original_lang == 'en':
                    display_question = ensure_pure_english(raw_question)
                    display_answer = ensure_pure_english(raw_answer)
                else:
                    display_question = translate_to_english_fast(raw_question)
                    display_answer = translate_to_english_fast(raw_answer)
            else:
                # ä¸­æ–‡å›ç­”
                if original_lang == 'zh':
                    display_question = ensure_pure_chinese(raw_question)
                    display_answer = ensure_pure_chinese(raw_answer)
                else:
                    display_question = translate_to_chinese_fast(raw_question)
                    display_answer = translate_to_chinese_fast(raw_answer)
            
            confidence = min(score / 10, 0.95)
            
            # ç¿»è¯‘ç±»å‹å’Œæ¥æº
            q_type = q.get('type', 'Medical')
            source = q.get('source', 'Medical Database')
            
            if answer_language == 'zh':
                if q_type == 'Fact Retrieval':
                    q_type = 'äº‹å®æ£€ç´¢'
                elif q_type == 'Medical':
                    q_type = 'åŒ»ç–—ä¿¡æ¯'
                if source == 'Medical Database':
                    source = 'åŒ»ç–—æ•°æ®åº“'
            
            results.append({
                'display_question': display_question,
                'display_answer': display_answer,
                'type': q_type,
                'source': source,
                'confidence': confidence,
                'original_lang': original_lang
            })
    
    # æ’åºå¹¶è¿”å›
    results.sort(key=lambda x: x['confidence'], reverse=True)
    
    # å»é‡
    unique_results = []
    seen_questions = set()
    
    for result in results:
        question_key = hashlib.md5(result['display_question'].encode()).hexdigest()
        if question_key not in seen_questions:
            seen_questions.add(question_key)
            unique_results.append(result)
        
        if len(unique_results) >= top_k:
            break
    
    return unique_results

# ========== Flaskè·¯ç”± ==========
@app.route('/')
def index():
    """ä¸»é¡µ"""
    doc_count, question_count, corpus_data, questions_data = get_data_counts()
    
    sample_questions = []
    if questions_data and 'sample_questions' in questions_data:
        all_samples = questions_data['sample_questions'][:20]
        if len(all_samples) >= 3:
            sample_questions = random.sample(all_samples, 3)
        else:
            sample_questions = all_samples
    
    display_questions = []
    for i, sq in enumerate(sample_questions):
        # ä½¿ç”¨ç®€æ˜“ç¿»è¯‘æ˜¾ç¤ºç¤ºä¾‹é—®é¢˜ï¼Œé¿å…å¡é¡¿
        question_text = sq.get('raw_question', '')
        if sq.get('original_lang') == 'en':
            display_text = simple_translate_to_chinese(question_text)
        else:
            display_text = question_text
        
        if len(display_text) > 40:
            display_text = display_text[:40] + "..."
        
        display_questions.append({
            'text': display_text,
            'full_question': question_text,
            'index': i,
            'lang': sq.get('original_lang', 'en')
        })
    
    return render_template('index.html',
                         doc_count=doc_count,
                         question_count=question_count,
                         sample_questions=display_questions)

@app.route('/api/query', methods=['POST'])
def handle_query():
    """å¤„ç†æŸ¥è¯¢è¯·æ±‚"""
    try:
        data = request.json
        question = data.get('question', '').strip()
        answer_language = data.get('answer_language', 'zh')
        
        if not question:
            return jsonify({'success': False, 'error': 'è¯·è¾“å…¥é—®é¢˜'})
        
        _, _, _, questions_data = get_data_counts()
        
        if not questions_data:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•åŠ è½½é—®é¢˜æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶'
            })
        
        search_results = search_in_questions(
            question, 
            questions_data, 
            answer_language=answer_language,
            top_k=5
        )
        
        answer_html = generate_answer_html(question, search_results, answer_language)
        
        result_count = len(search_results)
        if search_results:
            avg_confidence = sum(r.get('confidence', 0.5) for r in search_results) / result_count
        else:
            avg_confidence = 0
        
        has_chinese = any('\u4e00' <= char <= '\u9fff' for char in question)
        query_language = 'zh' if has_chinese else 'en'
        
        return jsonify({
            'success': True,
            'question': question,
            'answer': answer_html,
            'confidence': avg_confidence,
            'result_count': result_count,
            'query_language': query_language,
            'answer_language': answer_language
        })
    
    except Exception as e:
        print(f"æŸ¥è¯¢å¤„ç†é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        })

def generate_answer_html(question, search_results, answer_language='zh'):
    """ç”Ÿæˆå›ç­”HTML"""
    if not search_results:
        return f'''
        <div class="no-results">
            <h4>ğŸ¤” æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯</h4>
            <p>æš‚æ—¶æ²¡æœ‰æ‰¾åˆ°ä¸"<strong>{question}</strong>"ç›´æ¥ç›¸å…³çš„åŒ»ç–—ä¿¡æ¯ã€‚</p>
            <div class="suggestions">
                <p>å»ºè®®ï¼š</p>
                <ul>
                    <li>å°è¯•ä½¿ç”¨æ›´å…·ä½“çš„åŒ»ç–—æœ¯è¯­ï¼ˆå¦‚"ç³–å°¿ç—…ç—‡çŠ¶"ã€"é«˜è¡€å‹æ²»ç–—"ï¼‰</li>
                    <li>æ£€æŸ¥é—®é¢˜æ˜¯å¦åŒ…å«æ‹¼å†™é”™è¯¯</li>
                    <li>å°è¯•è¯¢é—®å¸¸è§ç–¾ç—…ï¼ˆå¦‚æ„Ÿå†’ã€å¤´ç—›ã€ç³–å°¿ç—…ç­‰ï¼‰</li>
                    <li>æ‚¨ä¹Ÿå¯ä»¥ç”¨è‹±æ–‡æé—®</li>
                </ul>
            </div>
        </div>
        '''
    
    html_parts = []
    
    html_parts.append('<div class="answer-container">')
    html_parts.append('<h4>ğŸ” æŸ¥è¯¢ç»“æœ</h4>')
    html_parts.append(f'<p class="query-display">é—®é¢˜ï¼š<strong>{question}</strong></p>')
    
    for i, result in enumerate(search_results, 1):
        display_question = result.get('display_question', '')
        display_answer = result.get('display_answer', '')
        source = result.get('source', 'åŒ»ç–—æ•°æ®åº“')
        q_type = result.get('type', 'åŒ»ç–—ä¿¡æ¯')
        confidence = result.get('confidence', 0.7) * 100
        
        html_parts.append(f'''
        <div class="search-result">
            <div class="result-header">
                <span class="result-number">#{i}</span>
                <span class="result-type">{q_type}</span>
                <span class="result-confidence">ç½®ä¿¡åº¦: {confidence:.0f}%</span>
            </div>
            <div class="result-content">
                <p><strong>ç›¸å…³ä¿¡æ¯:</strong> {display_question}</p>
                <div class="answer-box">
                    <strong>ç­”æ¡ˆ:</strong> {display_answer}
                </div>
                <p style="margin-top: 10px;"><strong>æ¥æº:</strong> <span class="source-badge">{source}</span></p>
            </div>
        </div>
        ''')
    
    advice = '''
    <div class="medical-advice">
        <h5>ğŸ’¡ åŒ»ç–—å»ºè®®</h5>
        <ul>
            <li>ä»¥ä¸Šä¿¡æ¯åŸºäºåŒ»ç–—æ•°æ®åº“ï¼Œä»…ä¾›å‚è€ƒ</li>
            <li>å…·ä½“ç—‡çŠ¶è¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ</li>
            <li>å¦‚é‡ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³å°±åŒ»</li>
            <li>ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼æœ‰åŠ©äºç–¾ç—…é¢„é˜²</li>
        </ul>
    </div>
    '''
    
    html_parts.append(advice)
    html_parts.append('</div>')
    return '\n'.join(html_parts)

@app.route('/api/export-data')
def export_data():
    """å¯¼å‡ºæ•°æ®ä¸ºExcel"""
    try:
        corpus_data = load_corpus_data()
        questions_data = load_questions_data()
        
        with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp:
            with pd.ExcelWriter(tmp.name, engine='openpyxl') as writer:
                if corpus_data and 'paragraphs' in corpus_data:
                    corpus_df = pd.DataFrame({
                        'Paragraph ID': [f'P{i+1:03d}' for i in range(len(corpus_data['paragraphs']))],
                        'Content': corpus_data['paragraphs'][:100],
                        'Character Count': [len(p) for p in corpus_data['paragraphs'][:100]]
                    })
                    corpus_df.to_excel(writer, sheet_name='Corpus Content', index=False)
                
                if questions_data and 'sample_questions' in questions_data:
                    questions_list = []
                    for i, q in enumerate(questions_data['sample_questions'][:200]):
                        questions_list.append({
                            'No.': i+1,
                            'Question (CN)': q.get('question_cn', ''),
                            'Question (EN)': q.get('question_en', ''),
                            'Answer (CN)': q.get('answer_cn', '')[:200] if q.get('answer_cn') else '',
                            'Answer (EN)': q.get('answer_en', '')[:200] if q.get('answer_en') else '',
                            'Type': q.get('type', 'Unknown'),
                            'Source': q.get('source', 'Unknown')
                        })
                    
                    questions_df = pd.DataFrame(questions_list)
                    questions_df.to_excel(writer, sheet_name='Question Samples', index=False)
                
                stats_data = [
                    {'Item': 'Corpus', 'Value': corpus_data['doc_count'] if corpus_data else 1, 'Description': 'Number of documents'},
                    {'Item': 'Question Set', 'Value': questions_data['total_count'] if questions_data else 0, 'Description': 'Total questions'},
                ]
                
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='Statistics', index=False)
            
            tmp_path = tmp.name
        
        return send_file(
            tmp_path,
            as_attachment=True,
            download_name='Medical_RAG_System_Data.xlsx',
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/data-stats')
def data_stats():
    """è·å–æ•°æ®ç»Ÿè®¡API"""
    doc_count, question_count, corpus_data, questions_data = get_data_counts()
    
    stats = {
        'corpus': {
            'document_count': doc_count,
            'corpus_name': corpus_data.get('corpus_name', 'åŒ»ç–—çŸ¥è¯†åº“') if corpus_data else 'Unknown',
            'has_data': corpus_data is not None
        },
        'questions': {
            'total_count': question_count,
            'type_count': len(questions_data.get('question_types', {})) if questions_data else 0,
            'has_data': questions_data is not None
        }
    }
    
    return jsonify({'success': True, 'data': stats})

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ¥ åŒè¯­åŒ»ç–—RAGé—®ç­”ç³»ç»Ÿ (ä¼˜åŒ–ç‰ˆï¼Œè§£å†³å¡é¡¿é—®é¢˜)")
    print("=" * 60)
    
    print("ğŸ“‚ æ£€æŸ¥æ•°æ®æ–‡ä»¶...")
    if CORPUS_PATH.exists():
        print(f"   âœ“ è¯­æ–™åº“æ–‡ä»¶: {CORPUS_PATH}")
    else:
        print(f"   âœ— è¯­æ–™åº“æ–‡ä»¶ä¸å­˜åœ¨: {CORPUS_PATH}")
        print(f"     è¯·å°† medical_corpus.json æ”¾ç½®åœ¨: {CORPUS_PATH}")
    
    if QUESTIONS_PATH.exists():
        print(f"   âœ“ é—®é¢˜é›†æ–‡ä»¶: {QUESTIONS_PATH}")
    else:
        print(f"   âœ— é—®é¢˜é›†æ–‡ä»¶ä¸å­˜åœ¨: {QUESTIONS_PATH}")
        print(f"     è¯·å°† medical_questions.json æ”¾ç½®åœ¨: {QUESTIONS_PATH}")
    
    doc_count, question_count, _, _ = get_data_counts()
    
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   è¯­æ–™åº“: {doc_count} ç¯‡æ–‡æ¡£")
    print(f"   é—®é¢˜é›†: {question_count} ä¸ªé—®é¢˜")
    
    print(f"\nğŸŒ è®¿é—®åœ°å€: http://localhost:5000")
    print(f"\nâš¡ ç³»ç»Ÿç‰¹æ€§:")
    print(f"   â€¢ æ”¯æŒä¸­è‹±æ–‡ä»»æ„è¯­è¨€æé—®")
    print(f"   â€¢ å¯é€‰æ‹©ä¸­æ–‡æˆ–è‹±æ–‡å›ç­”")
    print(f"   â€¢ ä½¿ç”¨translateåº“è¿›è¡Œé«˜è´¨é‡ç¿»è¯‘")
    print(f"   â€¢ æ™ºèƒ½å…³é”®è¯åŒ¹é…")
    print(f"   â€¢ æ•°æ®å¯¼å‡ºåŠŸèƒ½")
    print(f"   â€¢ ä¼˜åŒ–æ€§èƒ½ï¼Œé¿å…å¡é¡¿")
    
    print("\nğŸ¯ ä½¿ç”¨è¯´æ˜:")
    print(f"   1. åœ¨è¾“å…¥æ¡†ä¸­ç”¨ä¸­æ–‡æˆ–è‹±æ–‡æé—®")
    print(f"   2. é€‰æ‹©æƒ³è¦çš„å›ç­”è¯­è¨€ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰")
    print(f"   3. ç³»ç»Ÿä¼šè‡ªåŠ¨åŒ¹é…æœ€ç›¸å…³çš„é—®é¢˜å’Œç­”æ¡ˆ")
    print(f"   4. å¯ä»¥ç‚¹å‡»'ç¤ºä¾‹é—®é¢˜'å¿«é€Ÿæµ‹è¯•")
    
    print("=" * 60)
    
    # ç­‰å¾…ç¿»è¯‘é˜Ÿåˆ—åˆå§‹åŒ–
    time.sleep(1)
    
    os.makedirs('templates', exist_ok=True)
    
    app.run(debug=True, host='0.0.0.0', port=5000)